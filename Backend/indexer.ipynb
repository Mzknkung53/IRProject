{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 522517 recipes.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load recipe data from CSV\n",
    "recipes_df = pd.read_csv('../Resource/completed_recipes.csv')\n",
    "print(f\"Loaded {len(recipes_df)} recipes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch connect for now!!\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch(\n",
    "    \"https://localhost:9200\",\n",
    "    basic_auth=(\"elastic\", \"D*d4-0+Kl+lxfbbzh5ut\"),\n",
    "    ca_certs=\"~/http_ca.crt\"\n",
    ")\n",
    "\n",
    "if es.ping():\n",
    "    print(\"Elasticsearch connect for now!!\")\n",
    "else:\n",
    "    print(\"failed to connect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ned\\AppData\\Local\\Temp\\ipykernel_24548\\3960969787.py:11: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  es.indices.delete(index=index_name, ignore=[400, 404])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created index: recipes\n",
      "Indexed 1000 recipes into Elasticsearch.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from elasticsearch.helpers import bulk\n",
    "import re\n",
    "\n",
    "# Define index name and sample size for development\n",
    "index_name = \"recipes\"\n",
    "sample_size = 1000  # Set the sample size for testing (adjust as needed)\n",
    "\n",
    "# Delete the index if it already exists\n",
    "es.indices.delete(index=index_name, ignore=[400, 404])\n",
    "\n",
    "mapping = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"tokenizer\": {\n",
    "                \"ngram_tokenizer\": {\n",
    "                    \"type\": \"ngram\",\n",
    "                    \"min_gram\": 2,  # Minimum length of n-grams\n",
    "                    \"max_gram\": 3,  # Maximum length of n-grams\n",
    "                    \"token_chars\": [\"letter\", \"digit\"]\n",
    "                }\n",
    "            },\n",
    "            \"analyzer\": {\n",
    "                \"default\": {\n",
    "                    \"type\": \"english\"\n",
    "                },\n",
    "                \"ngram_analyzer\": {  # Custom N-gram analyzer for partial word search\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"ngram_tokenizer\",\n",
    "                    \"filter\": [\"lowercase\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"recipe_id\": {\"type\": \"keyword\"},\n",
    "            \"name\": { \n",
    "                \"type\": \"text\", \n",
    "                \"analyzer\": \"english\",\n",
    "                \"fields\": { \n",
    "                    \"ngram\": {  # N-gram variant for better partial matches\n",
    "                        \"type\": \"text\", \n",
    "                        \"analyzer\": \"ngram_analyzer\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"description\": {\"type\": \"text\", \"analyzer\": \"english\"},\n",
    "            \"instructions\": {\"type\": \"text\", \"analyzer\": \"english\"},\n",
    "            \"text\": {\"type\": \"text\", \"analyzer\": \"english\"},\n",
    "            \"calories\": {\"type\": \"float\"},\n",
    "            \"rating\": {\"type\": \"float\"},\n",
    "            \"image_url\": {\"type\": \"keyword\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "es.indices.create(index=index_name, body=mapping)\n",
    "print(f\"Created index: {index_name}\")\n",
    "\n",
    "recipes_sample = recipes_df.head(sample_size)\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Remove unwanted characters like c(\"...\"), quotes, and escape sequences.\"\"\"\n",
    "    if not isinstance(text, str):  \n",
    "        return \"\"  \n",
    "\n",
    "    text = re.sub(r'c\\(\"', '', text)\n",
    "    text = re.sub(r'\"\\)', '', text)\n",
    "\n",
    "    text = text.replace('\\\\\"', '')  \n",
    "    text = text.replace('\"', '')    \n",
    "    text = text.replace(\"\\\\\", '')  \n",
    "    cleaned_urls = re.sub(r'\\s+', ' ', text.strip())\n",
    "    # Split the string by ', ' (comma followed by a space)\n",
    "    urls = cleaned_urls.split(', ')\n",
    "    return urls\n",
    "\n",
    "def clean_instructions_combined_v2(instructions):\n",
    "    \"\"\"Cleans and formats recipe instructions into a single, well-structured sentence.\"\"\"\n",
    "    if isinstance(instructions, list):\n",
    "        instructions = \" \".join(instructions)  # Join list into a single string\n",
    "    \n",
    "    if not isinstance(instructions, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Remove unwanted wrapping (c(...)) and extra quotes\n",
    "    instructions = re.sub(r'c\\s*\\(\\s*', '', instructions)  # Remove \"c(\"\n",
    "    instructions = re.sub(r'\\s*\\)$', '', instructions)  # Remove trailing \")\"\n",
    "    instructions = instructions.strip('\"')\n",
    "\n",
    "    # Fix letter-by-letter spacing issues (e.g., \"M i x\" → \"Mix in\")\n",
    "    words = instructions.split()  # Split into words\n",
    "    cleaned_words = []\n",
    "    buffer = \"\"\n",
    "\n",
    "    for word in words:\n",
    "        if len(word) == 1:  # If it's a single letter, buffer it\n",
    "            buffer += word\n",
    "        else:\n",
    "            if buffer:\n",
    "                cleaned_words.append(buffer + word)  # Merge buffer with current word\n",
    "                buffer = \"\"\n",
    "            else:\n",
    "                cleaned_words.append(word)\n",
    "\n",
    "    if buffer:  # Append remaining buffered text\n",
    "        cleaned_words.append(buffer)\n",
    "\n",
    "    instructions = \" \".join(cleaned_words)\n",
    "\n",
    "    # Remove redundant punctuation and ensure proper spacing\n",
    "    instructions = re.sub(r'\\.\\s*\\.', '.', instructions)  # Remove repeated periods\n",
    "    instructions = re.sub(r'\\s*\\.\\s*', '. ', instructions)  # Ensure proper space after periods\n",
    "    instructions = re.sub(r'\\s*,', ',', instructions)  # Remove spaces before commas\n",
    "\n",
    "    # Remove leading/trailing unwanted characters (like extra quotes)\n",
    "    instructions = re.sub(r'(^\\\"|\\\"$)', '', instructions)  # Remove leading/trailing quotes\n",
    "\n",
    "    # Ensure proper formatting of sentences and remove unnecessary escape sequences\n",
    "    instructions = instructions.replace('\\\\\"', '')  # Remove escaped quotes\n",
    "    instructions = instructions.replace('\", \"', ', ')  # Convert improperly formatted list items into a natural sentence\n",
    "\n",
    "    # Convert sentence breaks into commas for a continuous explanation\n",
    "    instructions = re.sub(r'\\s*\\.\\s*', ', ', instructions)  # Convert periods into commas for a smoother flow\n",
    "\n",
    "    # Fix double commas and extra spaces\n",
    "    instructions = re.sub(r',\\s*,+', ', ', instructions)  # Remove repeated commas\n",
    "    instructions = re.sub(r'\\s+', ' ', instructions)  # Remove extra spaces\n",
    "\n",
    "    # Ensure only one period at the very end\n",
    "    instructions = instructions.strip().rstrip(',') + \".\"  # Remove trailing comma and add a period\n",
    "\n",
    "    return instructions\n",
    "\n",
    "\n",
    "\n",
    "def generate_docs(df):\n",
    "    for idx, row in df.iterrows():\n",
    "        recipe_id = str(int(float(row.get('RecipeId', idx))))\n",
    "        name = row.get('Name', '')\n",
    "        description = row.get('Description', '')  # Replacing \"ingredients\"\n",
    "        instructions = clean_instructions_combined_v2(row.get('RecipeInstructions', []))  # ✅ Clean instructions at indexing\n",
    "        text = clean_text(row.get('text', ''))  # Clean text\n",
    "        calories = float(row.get('Calories', 0))\n",
    "        image_url = row.get('image_link', [])\n",
    "\n",
    "        try:\n",
    "            rating = float(row['AggregatedRating']) if not np.isnan(row['AggregatedRating']) else 0\n",
    "        except (KeyError, TypeError, ValueError):\n",
    "            rating = 0\n",
    "        \n",
    "        doc = {\n",
    "            \"_op_type\": \"index\",\n",
    "            \"_index\": index_name,\n",
    "            \"_id\": recipe_id,\n",
    "            \"_source\": {\n",
    "                \"recipe_id\": recipe_id,\n",
    "                \"name\": name,\n",
    "                \"description\": description,  # Updated field\n",
    "                \"instructions\": instructions,  # ✅ Cleaned instructions\n",
    "                \"text\": text,  # Updated field\n",
    "                \"calories\": calories,\n",
    "                \"rating\": rating,\n",
    "                \"image_url\": image_url\n",
    "            }\n",
    "        }\n",
    "        if not np.isnan(row.get('AggregatedRating', np.nan)):\n",
    "            doc[\"_source\"][\"rating\"] = float(row[\"AggregatedRating\"])\n",
    "        yield doc\n",
    "\n",
    "\n",
    "bulk(es, generate_docs(recipes_sample))\n",
    "\n",
    "print(f\"Indexed {len(recipes_sample)} recipes into Elasticsearch.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from elasticsearch import Elasticsearch\n",
    "import re\n",
    "from flask_cors import CORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# Connect to Elasticsearch \n",
    "INDEX_NAME = \"recipes\"\n",
    "\n",
    "@app.route('/search', methods=['GET'])\n",
    "def search():\n",
    "    \"\"\"Search endpoint for querying recipes.\"\"\"\n",
    "    query = request.args.get('q', '')  \n",
    "    if not query:\n",
    "        return jsonify({\"error\": \"Query parameter 'q' is required\"}), 400\n",
    "    \n",
    "    # Elasticsearch search query\n",
    "    es_query = {\n",
    "        \"query\": {\n",
    "            \"multi_match\": {\n",
    "                \"query\": query,\n",
    "                \"fields\": [\"name^3\", \"description^2\", \"text\", \"name.ngram^2\"],  \n",
    "                \"fuzziness\": \"AUTO\" \n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    response = es.search(index=INDEX_NAME, body=es_query)\n",
    "    results = [\n",
    "        {\n",
    "            \"recipe_id\": hit[\"_source\"].get(\"recipe_id\"),\n",
    "            \"name\": hit[\"_source\"].get(\"name\"),\n",
    "            \"description\": hit[\"_source\"].get(\"description\"),  \n",
    "            \"text\": hit[\"_source\"].get(\"text\"), \n",
    "            \"image_url\": clean_text(hit[\"_source\"].get(\"image_url\")),\n",
    "            \"calories\": hit[\"_source\"].get(\"calories\"),\n",
    "            \"rating\": hit[\"_source\"].get(\"rating\", 0),\n",
    "            \"score\": hit[\"_score\"]\n",
    "            \n",
    "        }\n",
    "        for hit in response.get(\"hits\", {}).get(\"hits\", [])\n",
    "    ]\n",
    "    \n",
    "    return jsonify({\"results\": results})\n",
    "\n",
    "@app.route('/recipe/<recipe_id>', methods=['GET'])\n",
    "def get_recipe(recipe_id):\n",
    "    \"\"\"Fetches a single recipe by ID.\"\"\"\n",
    "    response = es.get(index=INDEX_NAME, id=recipe_id, ignore=[404])\n",
    "    \n",
    "    if response and response.get(\"found\"):\n",
    "        source = response[\"_source\"]\n",
    "        \n",
    "        # Clean instructions dynamically\n",
    "        source[\"instructions\"] = clean_instructions_combined_v2(source.get(\"instructions\", \"\"))\n",
    "        \n",
    "        # Clean image URL using clean_text\n",
    "        image_urls = clean_text(source.get(\"image_url\", \"\"))\n",
    "        source[\"image_url\"] = image_urls[0] if image_urls else \"\"\n",
    "\n",
    "        return jsonify(source)\n",
    "    \n",
    "    return jsonify({\"error\": \"Recipe not found\"}), 404\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
