{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 522517 recipes.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load recipe data from CSV\n",
    "recipes_df = pd.read_csv('../Resource/completed_recipes.csv')\n",
    "print(f\"Loaded {len(recipes_df)} recipes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch connect for now!!\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch(\n",
    "    \"https://localhost:9200\",\n",
    "    basic_auth=(\"elastic\", \"D*d4-0+Kl+lxfbbzh5ut\"),\n",
    "    ca_certs=\"~/http_ca.crt\"\n",
    ")\n",
    "\n",
    "if es.ping():\n",
    "    print(\"Elasticsearch connect for now!!\")\n",
    "else:\n",
    "    print(\"failed to connect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk, BulkIndexError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ned\\AppData\\Local\\Temp\\ipykernel_74668\\3854998588.py:6: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  es.indices.delete(index=index_name, ignore=[400, 404])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created index: recipes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing recipes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 522517/522517 [03:07<00:00, 2787.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 522517 recipes into Elasticsearch.\n"
     ]
    }
   ],
   "source": [
    "# --- Define Index Name ---\n",
    "index_name = \"recipes\"\n",
    "recipes_sample = recipes_df  # Use your dataset\n",
    "\n",
    "# --- Delete Index if Exists ---\n",
    "es.indices.delete(index=index_name, ignore=[400, 404])\n",
    "\n",
    "# --- Mapping: Updated image_url as text ---\n",
    "mapping = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"tokenizer\": {\n",
    "                \"ngram_tokenizer\": {\n",
    "                    \"type\": \"ngram\",\n",
    "                    \"min_gram\": 2,\n",
    "                    \"max_gram\": 3,\n",
    "                    \"token_chars\": [\"letter\", \"digit\"]\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"shingle_filter\": {\n",
    "                    \"type\": \"shingle\",\n",
    "                    \"min_shingle_size\": 2,\n",
    "                    \"max_shingle_size\": 3\n",
    "                }\n",
    "            },\n",
    "            \"analyzer\": {\n",
    "                \"default\": {\"type\": \"english\"},\n",
    "                \"ngram_analyzer\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"ngram_tokenizer\",\n",
    "                    \"filter\": [\"lowercase\"]\n",
    "                },\n",
    "                \"shingle_analyzer\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\"lowercase\", \"shingle_filter\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"recipe_id\": {\"type\": \"keyword\"},\n",
    "            \"name\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"english\",\n",
    "                \"fields\": {\n",
    "                    \"ngram\": {\"type\": \"text\", \"analyzer\": \"ngram_analyzer\"},\n",
    "                    \"shingle\": {\"type\": \"text\", \"analyzer\": \"shingle_analyzer\"}\n",
    "                }\n",
    "            },\n",
    "            \"description\": {\"type\": \"text\", \"analyzer\": \"english\"},\n",
    "            \"instructions\": {\"type\": \"text\", \"analyzer\": \"english\"},\n",
    "            \"text\": {\"type\": \"text\", \"analyzer\": \"english\"},\n",
    "            \"calories\": {\"type\": \"float\"},\n",
    "            \"rating\": {\"type\": \"float\"},\n",
    "            \"image_url\": {\"type\": \"text\"}  # Changed from keyword to text\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# --- Create Index ---\n",
    "es.indices.create(index=index_name, body=mapping)\n",
    "print(f\"Created index: {index_name}\")\n",
    "\n",
    "# --- Cleaning Functions ---\n",
    "\n",
    "def safe_text_field(value):\n",
    "    \"\"\"Convert NaN or None to empty string for text fields.\"\"\"\n",
    "    if isinstance(value, str):\n",
    "        return value.strip()\n",
    "    elif isinstance(value, float) and np.isnan(value):\n",
    "        return \"\"\n",
    "    elif value is None:\n",
    "        return \"\"\n",
    "    return str(value).strip()\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Remove unwanted characters like c(\"...\"), quotes, and escape sequences.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = re.sub(r'c\\(\"', '', text)\n",
    "    text = re.sub(r'\"\\)', '', text)\n",
    "    text = text.replace('\\\\\"', '').replace('\"', '').replace(\"\\\\\", '')\n",
    "    cleaned_urls = re.sub(r'\\s+', ' ', text.strip())\n",
    "    urls = cleaned_urls.split(', ')\n",
    "    return urls\n",
    "\n",
    "def clean_instructions_combined_v2(instructions):\n",
    "    if isinstance(instructions, list):\n",
    "        instructions = \" \".join(instructions)\n",
    "    if not isinstance(instructions, str):\n",
    "        return \"\"\n",
    "    instructions = re.sub(r'c\\s*\\(\\s*', '', instructions)\n",
    "    instructions = re.sub(r'\\s*\\)$', '', instructions)\n",
    "    instructions = instructions.strip('\"')\n",
    "    words = instructions.split()\n",
    "    cleaned_words = []\n",
    "    buffer = \"\"\n",
    "    for word in words:\n",
    "        if len(word) == 1:\n",
    "            buffer += word\n",
    "        else:\n",
    "            if buffer:\n",
    "                cleaned_words.append(buffer + word)\n",
    "                buffer = \"\"\n",
    "            else:\n",
    "                cleaned_words.append(word)\n",
    "    if buffer:\n",
    "        cleaned_words.append(buffer)\n",
    "    instructions = \" \".join(cleaned_words)\n",
    "    instructions = re.sub(r'\\.\\s*\\.', '.', instructions)\n",
    "    instructions = re.sub(r'\\s*\\.\\s*', '. ', instructions)\n",
    "    instructions = re.sub(r'\\s*,', ',', instructions)\n",
    "    instructions = re.sub(r'(^\\\"|\\\"$)', '', instructions)\n",
    "    instructions = instructions.replace('\\\\\"', '')\n",
    "    instructions = instructions.replace('\", \"', ', ')\n",
    "    instructions = re.sub(r'\\s*\\.\\s*', ', ', instructions)\n",
    "    instructions = re.sub(r',\\s*,+', ', ', instructions)\n",
    "    instructions = re.sub(r'\\s+', ' ', instructions)\n",
    "    instructions = instructions.strip().rstrip(',') + \".\"\n",
    "    return instructions\n",
    "\n",
    "def fix_image_url_field(image_url_raw):\n",
    "    \"\"\"Converts c(\"url1\", \"url2\") to list OR returns original list/string\"\"\"\n",
    "    if isinstance(image_url_raw, str) and image_url_raw.startswith(\"c(\"):\n",
    "        try:\n",
    "            fixed_str = image_url_raw.replace(\"c(\", \"[\").replace(\")\", \"]\")\n",
    "            return ast.literal_eval(fixed_str)\n",
    "        except Exception:\n",
    "            return [image_url_raw]\n",
    "    elif isinstance(image_url_raw, list):\n",
    "        return image_url_raw\n",
    "    elif isinstance(image_url_raw, str):\n",
    "        return [image_url_raw]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# --- Document Generator ---\n",
    "\n",
    "def generate_docs(df):\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Indexing recipes\"):\n",
    "        recipe_id = str(int(float(row.get('RecipeId', idx))))\n",
    "        name = safe_text_field(row.get('Name', ''))\n",
    "        description = safe_text_field(row.get('Description', ''))\n",
    "        instructions_raw = row.get('RecipeInstructions', [])\n",
    "        instructions = safe_text_field(clean_instructions_combined_v2(instructions_raw))\n",
    "        text_raw = row.get('text', '')\n",
    "        text_list = clean_text(text_raw)\n",
    "        text = \", \".join(text_list) if isinstance(text_list, list) else safe_text_field(text_list)\n",
    "        calories = float(row.get('Calories', 0))\n",
    "        image_url_raw = row.get('image_link', [])\n",
    "        image_urls = fix_image_url_field(image_url_raw)\n",
    "        image_url_final = image_urls[0] if isinstance(image_urls, list) and image_urls else \"\"\n",
    "        image_url_final = safe_text_field(image_url_final)\n",
    "        try:\n",
    "            rating = float(row['AggregatedRating']) if not np.isnan(row['AggregatedRating']) else 0\n",
    "        except (KeyError, TypeError, ValueError):\n",
    "            rating = 0\n",
    "        doc = {\n",
    "            \"_op_type\": \"index\",\n",
    "            \"_index\": index_name,\n",
    "            \"_id\": recipe_id,\n",
    "            \"_source\": {\n",
    "                \"recipe_id\": recipe_id,\n",
    "                \"name\": name,\n",
    "                \"description\": description,\n",
    "                \"instructions\": instructions,\n",
    "                \"text\": text,\n",
    "                \"calories\": calories,\n",
    "                \"rating\": rating,\n",
    "                \"image_url\": image_url_final\n",
    "            }\n",
    "        }\n",
    "        yield doc\n",
    "\n",
    "# --- Bulk Indexing ---\n",
    "\n",
    "try:\n",
    "    bulk(es, generate_docs(recipes_sample))\n",
    "    print(f\"Indexed {len(recipes_sample)} recipes into Elasticsearch.\")\n",
    "except BulkIndexError as e:\n",
    "    print(f\"Bulk index error: {len(e.errors)} documents failed.\")\n",
    "    for err in e.errors[:5]:\n",
    "        print(json.dumps(err, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import pymysql\n",
    "import numpy as np\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from werkzeug.security import generate_password_hash, check_password_hash\n",
    "from elasticsearch import Elasticsearch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Updated max_result_window to 100000 for index: recipes\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "app.secret_key = \"SOME_RANDOM_SECRET_KEY\"\n",
    "CORS(app)\n",
    "\n",
    "def get_db_connection():\n",
    "    return pymysql.connect(\n",
    "        host='127.0.0.1',\n",
    "        port=3309,\n",
    "        user='root',\n",
    "        password='root_password',\n",
    "        db='my_database',\n",
    "        cursorclass=pymysql.cursors.DictCursor\n",
    "    )\n",
    "\n",
    "\n",
    "INDEX_NAME = \"recipes\"\n",
    "\n",
    "try:\n",
    "    es.indices.put_settings(\n",
    "        index=INDEX_NAME,\n",
    "        body={\"index\": {\"max_result_window\": 100000}}\n",
    "    )\n",
    "    print(f\"âœ… Updated max_result_window to 100000 for index: {INDEX_NAME}\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Failed to update max_result_window: {str(e)}\")\n",
    "\n",
    "@app.route('/search', methods=['GET'])\n",
    "def search():\n",
    "    query = request.args.get('q', '').strip()\n",
    "    page = int(request.args.get('page', 1))\n",
    "    results_per_page = 10\n",
    "\n",
    "    if not query:\n",
    "        return jsonify({\"error\": \"Query parameter 'q' is required\"}), 400\n",
    "\n",
    "    # Log query to database\n",
    "    connection = get_db_connection()\n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(\"INSERT INTO search_logs (query) VALUES (%s)\", (query,))\n",
    "            connection.commit()\n",
    "    except Exception as log_error:\n",
    "        print(\"Search log error:\", log_error)\n",
    "    finally:\n",
    "        connection.close()\n",
    "\n",
    "    # Build Elasticsearch query\n",
    "    es_query = {\n",
    "        \"query\": {\n",
    "            \"multi_match\": {\n",
    "                \"query\": query,\n",
    "                \"fields\": [\"name^3\", \"description^2\", \"text\", \"name.ngram^2\"],\n",
    "                \"fuzziness\": \"AUTO\"\n",
    "            }\n",
    "        },\n",
    "        \"size\": results_per_page,\n",
    "        \"from\": (page - 1) * results_per_page,\n",
    "        \"suggest\": {\n",
    "            \"text\": query,\n",
    "            \"phrase_suggest\": {\n",
    "                \"phrase\": {\n",
    "                    \"field\": \"name.shingle\",\n",
    "                    \"size\": 1,\n",
    "                    \"gram_size\": 3,\n",
    "                    \"direct_generator\": [{\"field\": \"name.shingle\", \"suggest_mode\": \"always\"}],\n",
    "                    \"highlight\": {\"pre_tag\": \"<em>\", \"post_tag\": \"</em>\"}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Execute search\n",
    "        response = es.search(index=INDEX_NAME, body=es_query)\n",
    "        total_count = response[\"hits\"][\"total\"][\"value\"]\n",
    "\n",
    "        # ðŸ”¥ Debug print for development\n",
    "        print(f\"Total hits for '{query}':\", total_count)\n",
    "\n",
    "        hits = response.get(\"hits\", {}).get(\"hits\", [])\n",
    "\n",
    "        # Handle suggestion\n",
    "        suggested_query = ''\n",
    "        suggestions = response.get(\"suggest\", {}).get(\"phrase_suggest\", [])\n",
    "        if suggestions and suggestions[0][\"options\"]:\n",
    "            suggested_query = suggestions[0][\"options\"][0][\"text\"]\n",
    "\n",
    "        # ðŸš§ Pagination limit enforcement (Option A)\n",
    "        MAX_RESULT_WINDOW = 100000\n",
    "        max_allowed_pages = MAX_RESULT_WINDOW // results_per_page\n",
    "        if page > max_allowed_pages:\n",
    "            return jsonify({\n",
    "                \"results\": [],\n",
    "                \"total_count\": total_count,\n",
    "                \"suggested_query\": suggested_query,\n",
    "                \"warning\": f\"Cannot fetch page {page}. Maximum page allowed is {max_allowed_pages}.\"\n",
    "            })\n",
    "\n",
    "        # Format search results\n",
    "        results = [{\n",
    "            \"recipe_id\": hit[\"_source\"].get(\"recipe_id\"),\n",
    "            \"name\": hit[\"_source\"].get(\"name\"),\n",
    "            \"description\": hit[\"_source\"].get(\"description\"),\n",
    "            \"instructions\": hit[\"_source\"].get(\"instructions\"),\n",
    "            \"image_url\": clean_text(hit[\"_source\"].get(\"image_url\")),\n",
    "            \"calories\": hit[\"_source\"].get(\"calories\"),\n",
    "            \"rating\": hit[\"_source\"].get(\"rating\", 0),\n",
    "            \"score\": hit[\"_score\"]\n",
    "        } for hit in hits]\n",
    "\n",
    "        return jsonify({\n",
    "            \"results\": results,\n",
    "            \"total_count\": total_count,\n",
    "            \"suggested_query\": suggested_query\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": f\"Elasticsearch error: {str(e)}\"}), 500\n",
    "\n",
    "# ------------------ Recipe Details ------------------ #\n",
    "@app.route('/recipe/<recipe_id>', methods=['GET'])\n",
    "def get_recipe(recipe_id):\n",
    "    response = es.get(index=INDEX_NAME, id=recipe_id, ignore=[404])\n",
    "    if not response or not response.get(\"found\"):\n",
    "        return jsonify({\"error\": f\"Recipe ID {recipe_id} not found\"}), 404\n",
    "\n",
    "    source = response[\"_source\"]\n",
    "    source[\"instructions\"] = clean_instructions_combined_v2(source.get(\"instructions\", \"\"))\n",
    "    \n",
    "    cleaned_image = clean_text(source.get(\"image_url\", \"\"))\n",
    "    source[\"image_url\"] = cleaned_image[0] if isinstance(cleaned_image, list) and cleaned_image else \"\"\n",
    "\n",
    "    return jsonify(source)\n",
    "\n",
    "\n",
    "# ------------------ User Registration/Login ------------------ #\n",
    "@app.route('/register', methods=['POST'])\n",
    "def register():\n",
    "    data = request.json\n",
    "    username, password = data.get('username'), data.get('password')\n",
    "    if not username or not password:\n",
    "        return jsonify({\"error\": \"Missing username or password\"}), 400\n",
    "\n",
    "    password_hash = generate_password_hash(password)\n",
    "    connection = get_db_connection()\n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(\"SELECT user_id FROM users WHERE username = %s\", (username,))\n",
    "            if cursor.fetchone():\n",
    "                return jsonify({\"error\": \"Username already taken\"}), 400\n",
    "            cursor.execute(\"INSERT INTO users (username, password_hash) VALUES (%s, %s)\", (username, password_hash))\n",
    "            connection.commit()\n",
    "        return jsonify({\"message\": \"Registration successful\"}), 200\n",
    "    finally:\n",
    "        connection.close()\n",
    "\n",
    "@app.route('/login', methods=['POST'])\n",
    "def login():\n",
    "    data = request.json\n",
    "    username, password = data.get('username'), data.get('password')\n",
    "    if not username or not password:\n",
    "        return jsonify({\"error\": \"Missing username or password\"}), 400\n",
    "\n",
    "    connection = get_db_connection()\n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(\"SELECT user_id, password_hash FROM users WHERE username = %s\", (username,))\n",
    "            user = cursor.fetchone()\n",
    "            if not user or not check_password_hash(user['password_hash'], password):\n",
    "                return jsonify({\"error\": \"Invalid username or password\"}), 401\n",
    "\n",
    "            token = str(uuid.uuid4())\n",
    "            cursor.execute(\"REPLACE INTO sessions (token, username, user_id) VALUES (%s, %s, %s)\",\n",
    "                           (token, username, user['user_id']))\n",
    "            connection.commit()\n",
    "            return jsonify({\"message\": \"Login successful\", \"username\": username, \"token\": token}), 200\n",
    "    finally:\n",
    "        connection.close()\n",
    "\n",
    "@app.route('/logout', methods=['POST'])\n",
    "def logout():\n",
    "    auth_header = request.headers.get('Authorization')\n",
    "    if not auth_header or not auth_header.startswith('Bearer '):\n",
    "        return jsonify({\"error\": \"Invalid Authorization header format\"}), 401\n",
    "    token = auth_header.split(\" \")[1]\n",
    "\n",
    "    connection = get_db_connection()\n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(\"DELETE FROM sessions WHERE token = %s\", (token,))\n",
    "            connection.commit()\n",
    "        return jsonify({\"message\": \"Logged out successfully\"}), 200\n",
    "    finally:\n",
    "        connection.close()\n",
    "\n",
    "# ------------------ Top Searches ------------------ #\n",
    "@app.route('/top-searches', methods=['GET'])\n",
    "def top_searches():\n",
    "    connection = get_db_connection()\n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT query, COUNT(*) AS count \n",
    "                FROM search_logs \n",
    "                GROUP BY query \n",
    "                ORDER BY count DESC \n",
    "                LIMIT 5\n",
    "            \"\"\")\n",
    "            top_queries = cursor.fetchall()\n",
    "        return jsonify({\"top_searches\": top_queries}), 200\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": f\"Failed to fetch top searches: {str(e)}\"}), 500\n",
    "    finally:\n",
    "        connection.close()\n",
    "\n",
    "# ------------------ Recommendations ------------------ #\n",
    "@app.route('/recommendations', methods=['GET'])\n",
    "def recommendations():\n",
    "    auth_header = request.headers.get('Authorization')\n",
    "    if not auth_header or not auth_header.startswith('Bearer '):\n",
    "        return jsonify({\"error\": \"Invalid Authorization header format\"}), 401\n",
    "    token = auth_header.split(\" \")[1]\n",
    "\n",
    "    connection = get_db_connection()\n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(\"SELECT user_id FROM sessions WHERE token = %s\", (token,))\n",
    "            user = cursor.fetchone()\n",
    "            if not user:\n",
    "                return jsonify({\"error\": \"Invalid token\"}), 401\n",
    "            user_id = user['user_id']\n",
    "\n",
    "            cursor.execute(\"SELECT recipe_id FROM bookmarks WHERE user_id = %s\", (user_id,))\n",
    "            bookmarked_ids = [r[\"recipe_id\"] for r in cursor.fetchall()]\n",
    "\n",
    "        bookmarked_recipes = []\n",
    "        if bookmarked_ids:\n",
    "            import random\n",
    "            random.shuffle(bookmarked_ids)\n",
    "            picked = bookmarked_ids[:2]\n",
    "            for rid in picked:\n",
    "                res = es.get(index=INDEX_NAME, id=str(rid), ignore=[404])\n",
    "                if res and res.get(\"found\"):\n",
    "                    doc = res[\"_source\"]\n",
    "                    doc[\"image_url\"] = clean_text(doc.get(\"image_url\", \"\"))\n",
    "                    bookmarked_recipes.append(doc)\n",
    "\n",
    "        must_not_clause = []\n",
    "        if bookmarked_ids:\n",
    "            must_not_clause.append({\"terms\": {\"recipe_id\": [str(i) for i in bookmarked_ids]}})\n",
    "\n",
    "        es_query = {\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"must\": [{\"exists\": {\"field\": \"image_url\"}}],\n",
    "                    \"must_not\": must_not_clause\n",
    "                }\n",
    "            },\n",
    "            \"size\": 3\n",
    "        }\n",
    "\n",
    "        es_res = es.search(index=INDEX_NAME, body=es_query)\n",
    "        new_recipes = []\n",
    "        for hit in es_res.get(\"hits\", {}).get(\"hits\", []):\n",
    "            doc = hit[\"_source\"]\n",
    "            doc[\"image_url\"] = clean_text(doc.get(\"image_url\", \"\"))\n",
    "            new_recipes.append(doc)\n",
    "\n",
    "        return jsonify({\"recommendations\": bookmarked_recipes + new_recipes}), 200\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": f\"Error fetching recommendations: {str(e)}\"}), 500\n",
    "    finally:\n",
    "        connection.close()\n",
    "\n",
    "@app.route('/bookmark', methods=['POST'])\n",
    "def add_bookmark():\n",
    "    data = request.json or {}\n",
    "    auth_header = request.headers.get('Authorization')\n",
    "    if not auth_header or not auth_header.startswith('Bearer '):\n",
    "        return jsonify({\"error\": \"Invalid Authorization header format\"}), 401\n",
    "    token = auth_header.split(\" \")[1]\n",
    "\n",
    "    connection = get_db_connection()\n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(\"SELECT username FROM sessions WHERE token = %s\", (token,))\n",
    "            user = cursor.fetchone()\n",
    "            if not user:\n",
    "                return jsonify({\"error\": \"Invalid token\"}), 401\n",
    "            username = user['username']\n",
    "\n",
    "            recipe_id = data.get('recipe_id')\n",
    "            folder_name = data.get('folder_name', '').strip()\n",
    "            rating = data.get('rating', 0)\n",
    "\n",
    "            if not recipe_id or not folder_name:\n",
    "                return jsonify({\"error\": \"Missing recipe_id or folder_name\"}), 400\n",
    "\n",
    "            cursor.execute(\"SELECT id FROM folders WHERE username = %s AND folder_name = %s\", (username, folder_name))\n",
    "            folder_row = cursor.fetchone()\n",
    "            folder_id = folder_row['id'] if folder_row else None\n",
    "\n",
    "            if not folder_id:\n",
    "                cursor.execute(\"INSERT INTO folders (username, folder_name) VALUES (%s, %s)\", (username, folder_name))\n",
    "                folder_id = cursor.lastrowid\n",
    "\n",
    "            cursor.execute(\"INSERT IGNORE INTO folder_recipes (folder_id, recipe_id) VALUES (%s, %s)\", (folder_id, recipe_id))\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO bookmarks (user_id, recipe_id, rating)\n",
    "                VALUES ((SELECT user_id FROM users WHERE username = %s), %s, %s)\n",
    "                ON DUPLICATE KEY UPDATE rating = VALUES(rating)\n",
    "            \"\"\", (username, recipe_id, rating))\n",
    "            connection.commit()\n",
    "\n",
    "        return jsonify({\"message\": \"Bookmark added successfully\"}), 200\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": f\"Bookmark error: {str(e)}\"}), 500\n",
    "    finally:\n",
    "        connection.close()\n",
    "\n",
    "@app.route('/bookmarks', methods=['GET'])\n",
    "def get_bookmarks():\n",
    "    auth_header = request.headers.get('Authorization')\n",
    "    if not auth_header or not auth_header.startswith('Bearer '):\n",
    "        return jsonify({\"error\": \"Invalid Authorization header format\"}), 401\n",
    "    token = auth_header.split(\" \")[1]\n",
    "\n",
    "    connection = get_db_connection()\n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(\"SELECT username FROM sessions WHERE token = %s\", (token,))\n",
    "            user = cursor.fetchone()\n",
    "            if not user:\n",
    "                return jsonify({\"error\": \"Invalid token\"}), 401\n",
    "            username = user['username']\n",
    "\n",
    "            cursor.execute(\"SELECT id AS folder_id, folder_name FROM folders WHERE username = %s\", (username,))\n",
    "            folders = cursor.fetchall()\n",
    "\n",
    "            for folder in folders:\n",
    "                folder_id = folder[\"folder_id\"]\n",
    "                cursor.execute(\"\"\"\n",
    "                    SELECT fr.recipe_id, b.rating \n",
    "                    FROM folder_recipes fr\n",
    "                    LEFT JOIN bookmarks b ON fr.recipe_id = b.recipe_id \n",
    "                    AND b.user_id = (SELECT user_id FROM users WHERE username = %s)\n",
    "                    WHERE fr.folder_id = %s\n",
    "                    ORDER BY b.rating DESC\n",
    "                \"\"\", (username, folder_id))\n",
    "                recipes = cursor.fetchall()\n",
    "\n",
    "                for recipe in recipes:\n",
    "                    es_res = es.get(index=\"recipes\", id=str(recipe[\"recipe_id\"]), ignore=[404])\n",
    "                    if es_res and es_res.get(\"found\"):\n",
    "                        src = es_res[\"_source\"]\n",
    "                        recipe[\"image_url\"] = clean_text(src.get(\"image_url\", \"\"))\n",
    "                        recipe[\"name\"] = src.get(\"name\", \"\")\n",
    "                        recipe[\"description\"] = src.get(\"description\", \"\")\n",
    "\n",
    "                folder[\"recipes\"] = recipes\n",
    "\n",
    "        return jsonify({\"folders\": folders}), 200\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": f\"Bookmarks fetch error: {str(e)}\"}), 500\n",
    "    finally:\n",
    "        connection.close()\n",
    "\n",
    "@app.route('/bookmark', methods=['DELETE'])\n",
    "def delete_bookmark():\n",
    "    data = request.json or {}\n",
    "    auth_header = request.headers.get('Authorization')\n",
    "    if not auth_header or not auth_header.startswith('Bearer '):\n",
    "        return jsonify({\"error\": \"Invalid Authorization header format\"}), 401\n",
    "    token = auth_header.split(\" \")[1]\n",
    "\n",
    "    connection = get_db_connection()\n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(\"SELECT username FROM sessions WHERE token = %s\", (token,))\n",
    "            user = cursor.fetchone()\n",
    "            if not user:\n",
    "                return jsonify({\"error\": \"Invalid token\"}), 401\n",
    "            username = user['username']\n",
    "\n",
    "            folder_id = data.get('folder_id')\n",
    "            recipe_id = data.get('recipe_id')\n",
    "            if not folder_id or not recipe_id:\n",
    "                return jsonify({\"error\": \"Missing folder_id or recipe_id\"}), 400\n",
    "\n",
    "            cursor.execute(\"DELETE FROM folder_recipes WHERE folder_id = %s AND recipe_id = %s\", (folder_id, recipe_id))\n",
    "            cursor.execute(\"\"\"\n",
    "                DELETE FROM bookmarks \n",
    "                WHERE recipe_id = %s AND user_id = \n",
    "                (SELECT user_id FROM users WHERE username = %s)\n",
    "                AND NOT EXISTS (SELECT 1 FROM folder_recipes WHERE recipe_id = %s)\n",
    "            \"\"\", (recipe_id, username, recipe_id))\n",
    "            connection.commit()\n",
    "\n",
    "        return jsonify({\"message\": \"Bookmark deleted successfully\"}), 200\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": f\"Delete bookmark error: {str(e)}\"}), 500\n",
    "    finally:\n",
    "        connection.close()\n",
    "\n",
    "@app.route('/folder', methods=['DELETE'])\n",
    "def delete_folder():\n",
    "    data = request.json or {}\n",
    "    auth_header = request.headers.get('Authorization')\n",
    "    if not auth_header or not auth_header.startswith('Bearer '):\n",
    "        return jsonify({\"error\": \"Invalid Authorization header format\"}), 401\n",
    "    token = auth_header.split(\" \")[1]\n",
    "\n",
    "    connection = get_db_connection()\n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(\"SELECT username FROM sessions WHERE token = %s\", (token,))\n",
    "            user = cursor.fetchone()\n",
    "            if not user:\n",
    "                return jsonify({\"error\": \"Invalid token\"}), 401\n",
    "            username = user['username']\n",
    "\n",
    "            folder_id = data.get('folder_id')\n",
    "            if not folder_id:\n",
    "                return jsonify({\"error\": \"Missing folder_id\"}), 400\n",
    "\n",
    "            cursor.execute(\"DELETE FROM folder_recipes WHERE folder_id = %s\", (folder_id,))\n",
    "            cursor.execute(\"DELETE FROM folders WHERE id = %s AND username = %s\", (folder_id, username))\n",
    "            connection.commit()\n",
    "\n",
    "        return jsonify({\"message\": \"Folder and bookmarks deleted successfully\"}), 200\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": f\"Delete folder error: {str(e)}\"}), 500\n",
    "    finally:\n",
    "        connection.close()\n",
    "\n",
    "@app.route('/suggestions/<int:folder_id>', methods=['GET'])\n",
    "def generate_suggestions(folder_id):\n",
    "    auth_header = request.headers.get('Authorization')\n",
    "    if not auth_header or not auth_header.startswith('Bearer '):\n",
    "        return jsonify({\"error\": \"Invalid Authorization header format\"}), 401\n",
    "    token = auth_header.split(\" \")[1]\n",
    "\n",
    "    connection = get_db_connection()\n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(\"SELECT user_id FROM sessions WHERE token = %s\", (token,))\n",
    "            user = cursor.fetchone()\n",
    "            if not user:\n",
    "                return jsonify({\"error\": \"Invalid token\"}), 401\n",
    "            user_id = user['user_id']\n",
    "\n",
    "            cursor.execute(\"SELECT recipe_id FROM folder_recipes WHERE folder_id = %s\", (folder_id,))\n",
    "            folder_recipes = cursor.fetchall()\n",
    "\n",
    "        if not folder_recipes:\n",
    "            return jsonify({\"error\": \"Folder is empty, no suggestions can be generated.\"}), 400\n",
    "\n",
    "        folder_recipe_ids = [str(r['recipe_id']) for r in folder_recipes]\n",
    "\n",
    "        folder_texts = []\n",
    "        for rid in folder_recipe_ids:\n",
    "            res = es.get(index=INDEX_NAME, id=rid, ignore=[404])\n",
    "            if res.get(\"found\"):\n",
    "                src = res[\"_source\"]\n",
    "                combined = f\"{src.get('name', '')} {src.get('description', '')} {src.get('instructions', '')}\"\n",
    "                folder_texts.append(combined.strip())\n",
    "\n",
    "        es_query = {\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"must_not\": {\n",
    "                        \"terms\": {\"recipe_id\": folder_recipe_ids}\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"size\": 100\n",
    "        }\n",
    "\n",
    "        es_res = es.search(index=INDEX_NAME, body=es_query)\n",
    "        candidates = es_res.get(\"hits\", {}).get(\"hits\", [])\n",
    "\n",
    "        candidate_texts = []\n",
    "        candidate_meta = []\n",
    "        for hit in candidates:\n",
    "            src = hit[\"_source\"]\n",
    "            combined = f\"{src.get('name', '')} {src.get('description', '')} {src.get('instructions', '')}\"\n",
    "            candidate_texts.append(combined.strip())\n",
    "            candidate_meta.append({\n",
    "                \"recipe_id\": src.get(\"recipe_id\"),\n",
    "                \"name\": src.get(\"name\"),\n",
    "                \"description\": src.get(\"description\"),\n",
    "                \"instructions\": src.get(\"instructions\"),\n",
    "                \"image_url\": clean_text(src.get(\"image_url\", \"\")),\n",
    "                \"calories\": src.get(\"calories\"),\n",
    "                \"rating\": src.get(\"rating\", 0),\n",
    "                \"score\": 0\n",
    "            })\n",
    "\n",
    "        all_texts = folder_texts + candidate_texts\n",
    "        vectorizer = TfidfVectorizer(stop_words='english')\n",
    "        tfidf_matrix = vectorizer.fit_transform(all_texts)\n",
    "\n",
    "        folder_vecs = tfidf_matrix[:len(folder_texts)]\n",
    "        candidate_vecs = tfidf_matrix[len(folder_texts):]\n",
    "\n",
    "        sim_matrix = cosine_similarity(candidate_vecs, folder_vecs)\n",
    "        sim_scores = np.mean(sim_matrix, axis=1)\n",
    "\n",
    "        for i, score in enumerate(sim_scores):\n",
    "            candidate_meta[i]['score'] = float(score)\n",
    "\n",
    "        ranked = sorted(candidate_meta, key=lambda x: x['score'], reverse=True)[:10]\n",
    "        return jsonify({\"suggestions\": ranked}), 200\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": f\"Suggestion error: {str(e)}\"}), 500\n",
    "    finally:\n",
    "        connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [16/Mar/2025 22:17:40] \"OPTIONS /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:17:40] \"GET /top-searches HTTP/1.1\" 200 -\n",
      "C:\\Users\\Ned\\AppData\\Local\\Temp\\ipykernel_74668\\2227239018.py:242: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  res = es.get(index=INDEX_NAME, id=str(rid), ignore=[404])\n",
      "127.0.0.1 - - [16/Mar/2025 22:17:40] \"GET /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:18:28] \"OPTIONS /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:18:28] \"GET /top-searches HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:18:28] \"GET /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:21:06] \"OPTIONS /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:21:06] \"GET /top-searches HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:21:06] \"GET /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:21:47] \"OPTIONS /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:21:47] \"GET /top-searches HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:21:47] \"GET /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:21:59] \"GET /search?q=cake&page=1 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hits for 'cake': 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ned\\AppData\\Local\\Temp\\ipykernel_74668\\2227239018.py:123: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  response = es.get(index=INDEX_NAME, id=recipe_id, ignore=[404])\n",
      "127.0.0.1 - - [16/Mar/2025 22:22:02] \"GET /recipe/72813 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:22:05] \"OPTIONS /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:22:05] \"GET /top-searches HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:22:05] \"GET /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:25:13] \"OPTIONS /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:25:13] \"GET /top-searches HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:25:13] \"GET /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:25:49] \"OPTIONS /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:25:49] \"GET /top-searches HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:25:49] \"GET /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:25:50] \"GET /top-searches HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:25:50] \"GET /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:27:07] \"OPTIONS /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:27:07] \"GET /top-searches HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:27:07] \"GET /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:28:00] \"OPTIONS /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:28:00] \"GET /top-searches HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:28:00] \"GET /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:28:03] \"GET /top-searches HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:28:03] \"GET /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:28:08] \"GET /search?q=Fish&page=1 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hits for 'Fish': 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [16/Mar/2025 22:28:10] \"GET /search?q=Fish&page=2 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hits for 'Fish': 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [16/Mar/2025 22:28:12] \"GET /search?q=Fish&page=3 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hits for 'Fish': 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [16/Mar/2025 22:28:14] \"GET /search?q=Fish&page=4 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hits for 'Fish': 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [16/Mar/2025 22:28:15] \"GET /search?q=Fish&page=3 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hits for 'Fish': 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [16/Mar/2025 22:28:16] \"GET /search?q=Fish&page=2 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hits for 'Fish': 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [16/Mar/2025 22:28:16] \"GET /search?q=Fish&page=1 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hits for 'Fish': 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [16/Mar/2025 22:29:09] \"OPTIONS /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:29:09] \"GET /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:29:09] \"GET /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:29:10] \"GET /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:29:11] \"OPTIONS /bookmarks HTTP/1.1\" 200 -\n",
      "C:\\Users\\Ned\\AppData\\Local\\Temp\\ipykernel_74668\\2227239018.py:353: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  es_res = es.get(index=\"recipes\", id=str(recipe[\"recipe_id\"]), ignore=[404])\n",
      "127.0.0.1 - - [16/Mar/2025 22:29:11] \"GET /bookmarks HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:29:14] \"OPTIONS /suggestions/8 HTTP/1.1\" 200 -\n",
      "C:\\Users\\Ned\\AppData\\Local\\Temp\\ipykernel_74668\\2227239018.py:462: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  res = es.get(index=INDEX_NAME, id=rid, ignore=[404])\n",
      "127.0.0.1 - - [16/Mar/2025 22:29:14] \"GET /suggestions/8 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:37:05] \"OPTIONS /suggestions/8 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:37:05] \"GET /suggestions/8 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:37:09] \"GET /recipe/118 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:37:11] \"OPTIONS /suggestions/8 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:37:11] \"GET /suggestions/8 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:37:12] \"GET /recipe/72 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:37:13] \"GET /suggestions/8 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:37:15] \"GET /recipe/71 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:37:16] \"OPTIONS /suggestions/8 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:37:16] \"GET /suggestions/8 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:37:24] \"OPTIONS /bookmarks HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:37:24] \"GET /bookmarks HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:37:27] \"OPTIONS /suggestions/2 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:37:27] \"GET /suggestions/2 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:37:30] \"OPTIONS /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:37:30] \"GET /top-searches HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:37:30] \"GET /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:37:33] \"GET /top-searches HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:37:33] \"GET /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:38:20] \"GET /search?q=Chicken&page=1 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hits for 'Chicken': 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [16/Mar/2025 22:38:21] \"GET /search?q=Chicken&page=2 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hits for 'Chicken': 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [16/Mar/2025 22:38:42] \"GET /recipe/463779 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:38:44] \"OPTIONS /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:38:44] \"GET /top-searches HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:38:44] \"GET /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:38:45] \"GET /recipe/463779 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:38:57] \"OPTIONS /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:38:57] \"GET /top-searches HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:38:57] \"GET /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:38:58] \"OPTIONS /bookmarks HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:38:58] \"GET /bookmarks HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:39:06] \"OPTIONS /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:39:06] \"GET /top-searches HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:39:06] \"GET /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:39:08] \"GET /recipe/463779 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:39:13] \"OPTIONS /bookmark HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:39:13] \"POST /bookmark HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:39:29] \"OPTIONS /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:39:29] \"GET /top-searches HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:39:29] \"GET /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:44:54] \"GET /recipe/25249 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:45:09] \"OPTIONS /bookmark HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:45:09] \"POST /bookmark HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:45:11] \"OPTIONS /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:45:11] \"GET /top-searches HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 22:45:11] \"GET /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 23:00:45] \"GET /recipe/82018 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 23:00:54] \"OPTIONS /bookmark HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 23:00:54] \"POST /bookmark HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 23:00:56] \"OPTIONS /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 23:00:56] \"GET /top-searches HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 23:00:56] \"GET /recommendations HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
